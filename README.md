# LiveSpeak

A professional real-time speech recognition and translation web application built with Next.js and Web Speech API, featuring multilingual support for English, Arabic, and Bengali.

## âœ¨ Features

- ğŸ¤ **Live Speech Recognition**: Real-time transcription using device's built-in Web Speech API
- ğŸŒ **Multi-language Support**: **English, Arabic, and Bengali** with enhanced dialect support
- ğŸ”„ **Instant Translation**: Real-time translation between all supported languages
- ğŸ“± **Responsive Design**: Mobile-first design that works perfectly on all devices
- âš¡ **No External APIs**: Uses device's built-in speech recognition capabilities
- ğŸ¨ **Modern UI**: Built with shadcn/ui components and Tailwind CSS
- ğŸš€ **Beautiful Permission Modal**: Professional microphone access request with smooth animations
- ğŸ³ï¸ **Enhanced Language UI**: Native language names (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©, à¦¬à¦¾à¦‚à¦²à¦¾) with flag icons
- ğŸ“‹ **Copy Functionality**: Easy text copying with user feedback
- ğŸ¯ **Advanced Recognition**: Dialect-specific configurations for optimal accuracy

## ğŸš€ Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## ğŸ¯ How It Works

1. **Permission Request**: Beautiful modal requests microphone access on first visit
2. **Start Recording**: Click the "Start Recording" button to begin speech recognition
3. **Live Transcription**: See your speech transcribed in real-time as you speak
4. **Final Text**: View the complete transcription after you finish speaking
5. **Translation**: Get instant translation to your target language
6. **Clear**: Use the "Clear transcription" button to reset and start fresh

## ğŸŒ Supported Languages

### **English (en-US)**
- US English dialect support
- Optimized for American English recognition

### **Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)**
- **Saudi Arabic (ar-SA)** - Modern Standard Arabic
- **Egyptian Arabic (ar-EG)** - Colloquial Egyptian dialect
- **Palestinian Arabic (ar-PS)** - Palestinian dialect
- Enhanced maxAlternatives (5) for better dialect accuracy

### **Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)**
- **Bangladesh Bengali (bn-BD)** - Standard Bangladesh Bengali
- **Indian Bengali (bn-IN)** - Indian Bengali variations
- Enhanced maxAlternatives (4) for regional variations

## ğŸ› ï¸ Technology Stack

- **Frontend**: Next.js 15.5.0, React 19, TypeScript
- **UI Components**: shadcn/ui, Radix UI
- **Styling**: Tailwind CSS v4
- **Speech Recognition**: Web Speech API (device built-in)
- **Translation**: Client-side dictionary-based system
- **Deployment**: Netlify with static export
- **Testing**: MCP Playwright integration

## ğŸ“± Browser Compatibility

- **Chrome**: Full support with Web Speech API
- **Safari**: Full support with Web Speech API
- **Firefox**: Full support with Web Speech API
- **Edge**: Full support with Web Speech API
- **Mobile Browsers**: Optimized for mobile speech recognition

## ğŸš€ Deployment

LiveSpeak is deployed on Netlify and ready for production use:

- **Live Demo**: [https://livespeak.netlify.app/](https://livespeak.netlify.app/)
- **Static Export**: Optimized for CDN deployment
- **Performance**: Fast loading with minimal bundle size

## ğŸ”§ Development

### Prerequisites
- Node.js 18 or higher
- npm, yarn, pnpm, or bun

### Installation
```bash
git clone https://github.com/khurramsaadat/livespeak2.git
cd livespeak
npm install
npm run dev
```

### Build for Production
```bash
npm run build
npm run export
```

## ğŸ“š Learn More

To learn more about the technologies used:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) - browser speech recognition and synthesis
- [shadcn/ui](https://ui.shadcn.com/) - beautiful and accessible UI components
- [Tailwind CSS](https://tailwindcss.com/) - utility-first CSS framework

## ğŸ¤ Contributing

This project is open source and contributions are welcome! Check out [the LiveSpeak GitHub repository](https://github.com/khurramsaadat/livespeak2.git) for more details.

### Development Guidelines
- Follow TypeScript best practices
- Use MCP Playwright for testing
- Maintain responsive design principles
- Add comprehensive error handling

## ğŸ“Š Project Status

**Current Status**: âœ… **MVP COMPLETED & DEPLOYED**

- âœ… All core PRD requirements implemented
- âœ… Multilingual support (English, Arabic, Bengali)
- âœ… Beautiful permission modal
- âœ… Enhanced language UI with native names
- âœ… Netlify deployment ready
- âœ… Comprehensive testing with MCP Playwright

**Next Phase**: Advanced features including cross-language recognition, RTL support, and enhanced translation quality.

## ğŸ“„ License

This project is licensed under the MIT License.

---

**Built with â¤ï¸ using Next.js, Web Speech API, and modern web technologies**
